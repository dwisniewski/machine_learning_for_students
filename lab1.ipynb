{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Regresja liniowa\n",
    "Poniższy kod przedstawia szablon implementacji regresji liniowej dla jednej zmiennej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_regression \n",
    "%matplotlib inline\n",
    "\n",
    "sizes = np.loadtxt('flat.areas').reshape((26,1)) #załaduj wektor rozmiarów mieszkań\n",
    "prices = np.loadtxt('flat.prices').reshape((26,1)) #załaduj wektor cen mieszkań\n",
    "samples_cnt = len(prices) #pobierz liczność par rozmiar->cena\n",
    "weight0 = 0.0 # inicjalizuj wagi\n",
    "weight1 = 0.0 #\n",
    "learning_rate = 0.0001 #stala uczenia\n",
    "maxIteration = 100000 #liczba iteracji\n",
    "\n",
    "for i in range(maxIteration):\n",
    "    weight0 = weight0\n",
    "    weight1 = weight1\n",
    "    \n",
    "    #Zadanie1: \n",
    "    predicted_prices = []\n",
    "    #uzupełnij listę predicted_prices tak, aby dla każdego metrazu budynku z listy 'sizes' wyznaczyć cenę tegoż\n",
    "    #budynku przy użyciu aktualnych wag modelu liniowego\n",
    "    \n",
    "    #Zadanie2:\n",
    "    #napisz kod, który iteracyjnie poprawiać będzie wagi tak, aby ostatecznie wyznaczyły prostą,\n",
    "    #która najlepiej odwzoru je zależność metraż -> cena\n",
    "    \n",
    "plt.plot(sizes, prices, \"x\")\n",
    "if len(predicted_prices) > 0:\n",
    "    plt.plot(sizes, predicted_prices, \"r-\")\n",
    "plt.title('Ceny mieszkan w zaleznosci od metrazu')\n",
    "plt.xlabel('metraz (m^2)')\n",
    "plt.ylabel('Cena mieskania (tys. zł)')\n",
    "plt.show()\n",
    "print(\"Wyznaczone wartości wag -> w0:\", weight0, \"w1:\", weight1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import visualize_cost_function\n",
    "import numpy as np\n",
    "\n",
    "def loss_function(sizes, prices, weight0, weight1):\n",
    "    predictions = [weight0 + weight1*sizes[i] for i in range(len(prices))]\n",
    "    return sum([(predictions[i] - prices[i])**2 for i in range(len(prices))])/(2*len(prices))\n",
    "\n",
    "\n",
    "def loss_function2(sizes, prices, weight0, weight1):\n",
    "    predictions = [weight0 + weight1*sizes[i] for i in range(len(prices))]\n",
    "    return sum([(np.sin(predictions[i]/prices[i]**2) * (predictions[i]*prices[i]**3)) for i in range(len(prices))])/(2*len(prices))\n",
    "\n",
    "\n",
    "#Poniższy kod wyznacza wartości funkcji kosztu w dziedzinie wartości atrybutów w0 i w1\n",
    "w0_values = np.arange(-10, 10, 0.5)\n",
    "w1_values = np.arange(-10, 10, 0.5)\n",
    "\n",
    "sizes_transformed = (sizes - np.mean(sizes)) / np.std(sizes)\n",
    "prices_transformed = (prices - np.mean(prices)) / np.std(prices)\n",
    "\n",
    "w0_values = np.arange(-100, 100, 5)\n",
    "w1_values = np.arange(-100, 100, 5)\n",
    "\n",
    "visualize_cost_function(sizes_transformed, prices_transformed, w0_values, w1_values, loss_function)\n",
    "visualize_cost_function(sizes_transformed, prices_transformed, w0_values, w1_values, loss_function2)\n",
    "\n",
    "#Zad 3\n",
    "#Po wykonaniu tego fragmentu kodu zobaczysz wizualizacje dwóch różnych funkcji kosztu. \n",
    "#Pierwsza z nich obrazuje błąd średniokwadratowy, druga - jakąś arbitralnie wybraną funkcję\n",
    "#Zastanów się, dlaczego używa się często tej pierwszej w procesie uczenia spadkiem gradientowym, a nie tej drugiej?\n",
    "#Co sprawia, że funkcja kosztu jest dobra?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regresja wielomianowa\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split # model_selection w starszych wersjach -> cross_validation\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#funkcja, ktora chcemy aproksymowac\n",
    "def f(x): \n",
    "\treturn -(3*x)+(7*x**2)-(3*x**3)\n",
    "\n",
    "x = np.linspace(0,1,100) #Stworzenie przestrzeni w której będziemy wizualizować aproksymowaną funkcję (x od 0 do 1 z krokiem 1/100)\n",
    "\n",
    "X = np.random.uniform(0, 1, size=50)[:, np.newaxis] #Wylosowanie przykladow (os X)\n",
    "y = f(X) + np.random.normal(scale=0.3, size=50)[:, np.newaxis] #Wygenerowanie punktów zgodnie z funkcją f(x) z uwzględnieniem szumu\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7) #Podzial danych na zbior treningowy i testowy\n",
    "\n",
    "\n",
    "#Pomocnicza funkcja do wizualizacji\n",
    "def plot_approximation(est, ax, label=None):\n",
    "    ax.plot(x, f(x), color='green')\n",
    "    ax.scatter(X_train, y_train, s=10) #Dodanie punktow zbioru treningowego do wizualizacji\n",
    "    ax.scatter(X_test, y_test, s=10, color='green', alpha=0.2) #Dodanie punktow zbioru testowego do wizualizacji\n",
    "    ax.plot(x, est.predict(x[:, np.newaxis]), color='red', label=label) #Wizualizacja wygenerowanej funkcji\n",
    "    ax.set_ylim((-2, 2))\n",
    "    ax.set_xlim((0, 1))\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "#Uzycie sklearn do wygenerowania regresji wielomianowej stopnia 0,1,3,9\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 5))\n",
    "for ax, degree in zip(axes.ravel(), [0, 1, 3, 9]):\n",
    "    est = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    est.fit(X_train, y_train)\n",
    "    plot_approximation(est, ax, label='stopien=%d' % degree)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Uzycie sklearn do wygenerowania regresji wielomianowej stopnia 0..15, w celu weryfikacji bledu na zbiorach uczacym i testowym\n",
    "train_error = np.empty(15)\n",
    "test_error = np.empty(15)\n",
    "for degree in range(15):\n",
    "    est = make_pipeline(PolynomialFeatures(degree), LinearRegression()) #Zdefiniowanie typu modelu\n",
    "    est.fit(X_train, y_train)  #Uczenie parametrów\n",
    "    train_error[degree] = mean_squared_error(y_train, est.predict(X_train)) #Zapisanie bledu zb. uczacego dla zadanego stopnia wielomianu\n",
    "    test_error[degree] = mean_squared_error(y_test, est.predict(X_test)) #Zapisanie bledu zb. testowego dla zadanego stopnia wielomianu\n",
    "    \n",
    "    \n",
    "#Wizualizacja bledu. Odpowiednio na zbiorze uczacym i testowym\n",
    "plt.plot(np.arange(15), train_error, color='green', label='blad na zbiorze treningowym')\n",
    "plt.plot(np.arange(15), test_error, color='red', label='blad na zbiorze testowym')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.ylim((0.0, 1e0))\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('stopien wielomianu')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Zadanie 4:\n",
    "#Zastanow sie dlaczego powyzej pewnego stopnia wielomianu blad na zbiorze testowym staje sie coraz wiekszy?\n",
    "#Po co wprowadza się zbiór testowy?\n",
    "\n",
    "\n",
    "#Zadanie 5:\n",
    "#Podmieniając LinearRegression przez Ridge, sprawdź jaki wpływ ma regularyzacja na błąd testowy. \n",
    "#Zaobserwuj różnicę w wyglądzie wygenerowanej krzywej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
