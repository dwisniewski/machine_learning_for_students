{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "conda install -y h5py seaborn scikit-learn\n",
    "\n",
    "pip install tensorflow \n",
    "\n",
    "git clone git@github.com:fchollet/keras.git && cd keras && python setup.py install (w sali nie ma pewnie zainstalowanego gita, więc zainstalowanie kerasa sprowadzi się do wejścia na github.com/fchollet i sklonowania projektu keras poprzez ściągnięcie go jako archiwum *.zip, rozpakowanie a następnie wywołanie python setup.py install)\n",
    "\n",
    "ściągnać dane z https://drive.google.com/open?id=0B7Q76BJpVecSQVlCUER6X3U0ejA (256MB) i rozpakować w folderze z notebookiem (folder data powinien pojawić się w głównym folderze z notebookiem)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Uczenie głębokie z wykorzystaniem dedykowanych narzędzi\n",
    "\n",
    "### Spis treści:\n",
    "    1) Wstęp: oprogramowanie dedykowane sieciom neuronowym\n",
    "    2) Wstep do obliczeń symbolicznych\n",
    "    3) Keras\n",
    "    4.) Hands-on computer vision: prezentacja i ćwiczenie z rozponawania obrazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.)  Wstęp: oprogramowanie dedykowane sieciom neuronowym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wraz z rosnącym zainteresowaniem sieciami neuronowymi, rosło zapotrzebowanie na dedykowane narzędzia, które ułatwiłyby i przyspieszyły proces tworzenia, a następnie uczenia głębokich modeli. \n",
    "\n",
    "\n",
    "- Z upływem lat kolejne grupy badawcze prezentowały swoje rozwiązania, a w ostatnim czasie tematem zainteresował się również przemysł. Dzięki nowym źródłom finansowania i niesłabnącemu zapotrzebowaniu, większość frameworków jest obecnie aktywnie rozwijana i ulepszana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do najpopularniejszych narzędzi należą:\n",
    "\n",
    "    - [Tensorflow](http://tensorflow.org) (**Google**)\n",
    "        - Python, Go, C++\n",
    "        - Najpopularniejszy z obecnie istniejących frameworków\n",
    "        - Najintensywniej rozwijany\n",
    "\n",
    "    - [Theano](http://deeplearning.net/software/theano/) (**U. Montreal**)\n",
    "        - Python\n",
    "        - Był prekursorem TensorFlow\n",
    "        - Rozwijany przez uniwersytet w Montrealu (non-profit)\n",
    "        - Obecnie coraz częściej porzucany na rzecz TF\n",
    "\n",
    "    - [Torch](http://torch.ch/) (**Facebook, Twitter**)\n",
    "        - Lua\n",
    "        - Najmniej popularny ze względu na brak bindingów Pythonoych\n",
    "        - Nie wspiera automatycznego różniczkowania\n",
    "\n",
    "    - [MXNet](http://mxnet.io/) (**Amazon**)\n",
    "        - Python, C++, Go, Julia, Scala, R, ...\n",
    "        - Najwydajniejszy pod względem pamięci \n",
    "        - Od niedawna wspierany przez Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"img/tf-logo-2.png\"> \n",
    "<img style=\"float: left;\" src=\"img/th-logo.png\">\n",
    "<img style=\"float: left;\" src=\"img/torch-logo-f.png\">\n",
    "<img style=\"float: left;\" src=\"img/mx-logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wszystkie z tych narzędzi są rozwijane jako proejkty OpenSource:\n",
    "\n",
    "    - https://github.com/tensorflow/tensorflow\n",
    "\n",
    "    - https://github.com/torch/torch7\n",
    "\n",
    "    - https://github.com/Theano/Theano\n",
    "\n",
    "    - https://github.com/dmlc/mxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wymienione wyżej narzędzia to zazwyczaj biblioteki operujące na dosyć niskim poziomie abstrakcji.\n",
    "\n",
    "- Wokół nich powstało wiele projektów mających jeszcze bardziej ułatwić użytkownikom uczenie sieci neuronowych.\n",
    "\n",
    "- Najpopularniejszym z takich projektów jest obecnie **Keras**, na którym skupimy się w dalszej części\n",
    "\n",
    "![k](img/keras-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.) Wstep do obliczeń symbolicznych\n",
    "\n",
    "- Sercem większości frameworków wysokiego poziomu jest jeden z wyżej wymienionych silników.\n",
    "- Keras, którego będziemy dzisiaj używać, posiada dwa takie backendy: Tensorflow oraz Theano\n",
    "- Warto poświęcić chwilę, żeby zapoznać się z najbardziej podstawowymi zastadami ich działania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Tensorflow i Theano to przykłady narzędzi, które tworzą graf operacji symbolicznych.\n",
    "\n",
    "- Oznacza to, że operacje wykonywane na zmiennych nie mają natychmiastowego efektu. Są jedynie dodawane do grafu.\n",
    "\n",
    "- Następnie graf jest kompilowany i wykonwyany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from helpers3 import show_graph\n",
    "from helpers3 import execute_tf_graph\n",
    "\n",
    "def get_tf_graph():\n",
    "    return tf.get_default_graph().as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(2.)\n",
    "b = tf.Variable(2.)\n",
    "result = a + b\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`result` nie jest równe 4! \n",
    "\n",
    "Jest tylko węzłem w grafie, symbolizującym operację dodania zmiennej `a` do `b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = get_tf_graph()\n",
    "\n",
    "show_graph(graph_def=graph, width=900, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbudowany graf możemy \"wykonać\", jako parametr `outptus` podając te zmienne, które chcemy obliczyć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execute_tf_graph(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobrze, ale co zrobić, jeżeli chcemy obliczyć sumę `2 + 3`. Czy musimy zbudować i skompilować cały graf od nowa?\n",
    "\n",
    "Na szczęście nie -- możemy podać wartości dowolnej zmiennej w grafie przy jego wywołaniu.\n",
    "\n",
    "Aby to zrobić, tworzymy słownik, który przypisze wybranym zmiennym odpowiednie wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    a: 2,\n",
    "    b: 3\n",
    "}\n",
    "\n",
    "execute_tf_graph(outputs=result, inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwróć uwagę, że w słowniku tym nie podajemy nazw zmiennych (typu `str`), ale obiekty `Pythona`!\n",
    "\n",
    "**Uwaga!**: w praktyce, jeżeli chcemy, żeby nasza zmienna była inicjalizowana dopiero przy wywołaniu grafu, \n",
    "oraz żeby jej podanie było obowiązkowe, należy **tf.Variable** zamienić na **tf.placeholder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.placeholder(dtype=np.float32, name='zmienna_a')\n",
    "result = a + 1\n",
    "\n",
    "try:\n",
    "    execute_tf_graph(result)\n",
    "except tf.python.errors.InvalidArgumentError as e:\n",
    "    print(e.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### zadanie 1: \n",
    "    - oblicz kwadraty liczb 2, 3 i 4 używając tensorflow. Wykorzystaj mechanizm placeholderów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### rozwiązanie 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tutaj rozwiązanie zadania 1#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### zadanie 2: \n",
    "    - dodaj dwie macierze jednostkowe 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### rozwiązanie 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tutaj rozwiązanie zadania 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Warto zaznaczyć, iż **Tensorflow został stworzony dla operacji na macierzach (tensorach)**. Radzi więc sobie wspaniale z wielowymiarowymi danymi. (Patrz rozw. powyżej)\n",
    "\n",
    "- Jakie są jednak konkretne zalety tego symbolicznego podejścia? Trzy najważniejsze to:\n",
    "    1. Optymalizacja: znając cały graf, kompilator może zoptymalizować wykonywane operacje\n",
    "    2. Współbieżność: kompilator sam zadba o to, aby wykonać obliczenia równolegle\n",
    "    3. Niezależność od architektury: Znając graf, kompilator może wygenerować kod dla CPU / GPU / FPGA etc.\n",
    "    \n",
    "- Szczególnie punkt trzeci jest tak istotny, gdyż obecnie do uczenia sieci neuronowych niemalże niezbędny jest procesor graficzny wspierający technologię `CUDA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czym is Keras?\n",
    "\n",
    "Za https://keras.io:\n",
    "\n",
    "> ### Keras: Deep Learning library for Theano and TensorFlow\n",
    ">\n",
    "> Keras is a **high-level neural networks** library, written in **Python** and capable of running on top of either **TensorFlow** or **Theano**. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "- Jest to biblioteka mająca ułatwić tworzenie sieci neuronowych, operująca na wyższym poziomie abstrakcji niż tensorflow / theano\n",
    "- Jako backendu obliczeniowego może wykorzystywać jeden z wyżej wymienionych silników\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dlaczego Keras?\n",
    "\n",
    "- Łatwy do opanowania\n",
    "- Czytelny\n",
    "- Popularny i aktywnie rozwijany \n",
    "- Dobrze udokumentowany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak nauczyć sieć neuronową?\n",
    "\n",
    "Będziemy potrzebować trzech elementów:\n",
    "1. Dane\n",
    "2. Architektura sieci\n",
    "3. Metoda optymalizacji\n",
    "    - Funkcja straty\n",
    "    - Algorytm optymalizacyjny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Dane\n",
    "\n",
    "- Keras współpracuje z numpy, w związku z tym można korzystać z dowolnego zbioru danych, który jesteśmy w stanie wczytać do pamięci.\n",
    "- Może korzystać ze zbiorów zbyt dużych, żeby zmieśćić się w pamięci: potrzebna jest wtedy biblioteka `h5py`\n",
    "- Posiada także kilka wbudowanych zbiorów danych, jak np. mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
    "- klasyczny benchmark w computer vision (ponad 700 cytowań w pracach naukowych)\n",
    "- 60 000 obrazów przedstawiających cyfry napisane ludzką ręką\n",
    "- Można załadować bezpośrednio z kerasa\n",
    "\n",
    "![mnist](img/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "img_size = 28\n",
    "\n",
    "print(\"Wymiary zbioru, X: {}, y: {}\".format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowanie danych: \n",
    "    - Obrazy, które trafiają do sieci neuronowej muszą mieć odpowiedni \"kształt\" (shape) oraz typ: \n",
    "        - (liczba_przykładóœ, szerokość, wysokość, liczba-kanałóœ) \n",
    "        - typem danych powinien być float32, a elementy macierzy powinny być w zakresie [0., 1.]\n",
    "    - Etykiety (informacja, którą cyfrę przedstawia dany obrazek), powinny mieć kształt (liczba_przykładów, liczba_cyfr) patrz poniżej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras oczekuje, iż etykiety będą macierzą binarną o kształcie (liczba_przykładów, liczba_możliwych_etykiet)\n",
    "# Mówimy, że dany obraz należy do klasy **i**, kiedy w kolumnie **i-tej** znajduje się 1\n",
    "# przykład:\n",
    "etykiety = [\n",
    "    0,\n",
    "    1,\n",
    "    2\n",
    "]\n",
    "\n",
    "etykiety_keras = [\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "# aby zamienić etykiety wczytane przez mnist.load_data(), skorzystamy z funkcji pomocniczej kerasa \"to_categorical\":\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test  = np_utils.to_categorical(y_test,  10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Przygotujmy też same obrazki\n",
    "rozmiar = 28\n",
    "X_train = X_train.reshape(-1, rozmiar, rozmiar, 1)\n",
    "X_test  = X_test.reshape(-1,  rozmiar, rozmiar, 1)\n",
    "\n",
    "X_train = X_train.astype(np.float32) / 255.\n",
    "X_test  = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sprawdzźmy, jak wyglądają nasze dane:\n",
    "i = np.random.randint(0, y_train.shape[0])\n",
    "\n",
    "print(\"Label: \", y_train[i])\n",
    "sns.heatmap(X_train[i].reshape(rozmiar, rozmiar));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Architektura sieci\n",
    "- Keras wspiera dwie metody definiowania architektury: model liniowy i API funkcjonalne.\n",
    "- Skupimy się dzisiaj głównie na modelach liniowych, ponieważ w zupełności wystarczają one do większośći zastosowań praktycznych.\n",
    "- Kluczowym pojęciem przy definiowaniu architektury jest pojęcie **warstwy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Warstwy:\n",
    "\n",
    "- Podstawowym elementem, z którego budowana jest sieć neuronowa, jest warstwa. \n",
    "- Model liniowy w kerasie to nic innego, jak tylko złożenie kolejnych, następujących po sobie warstw.\n",
    "- Warstwa (layer) jest podstawową jednostką przetwarzania: \n",
    "- przyjmuje ona jakąś macierz (tensor) na wejściu, modyfikuje ją, a następnie podaje na wyściu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "\n",
    "from helpers3 import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aby zobrazować to w praktyce, zaimplementujemy regresję logistyczną, poznaną na poprzednich zajęciach, z użyciem kerasa\n",
    "\n",
    "# zdefiniujmy sobie najpierw warstwy, których użyjemy:\n",
    "\n",
    "# regresja logistyczna oczekuje jednowymiarowego wektora cech. Obrazki to macierze kwadratowe, należy je \"słaszczyć\"\n",
    "flatten_layer = Flatten(input_shape=(rozmiar, rozmiar, 1))\n",
    "\n",
    "# następnie wektor cech jest mnożony przez macierz wag. Macierz wag ma rozmiar (liczba_cech x liczba_klas)\n",
    "# Keras sam odgadnie, jaka jest liczba cech! Podajemy jedynie liczbę klas.\n",
    "# Warstwą realizującą mnożenie macierzy jest warstwa Dense:\n",
    "matmul_layer = Dense(10)\n",
    "\n",
    "# Teraz nasz model pobiera na wejściu obrazek 20x20, a generuje wektor o rozmiarze (10, ), \n",
    "# gdzie każdy element tego wektora to \"wynik\" danej klasy. Należy zamienić jeszcze ten wynik na prawdopodobieństwa\n",
    "get_probas_layer = Activation(\"softmax\")\n",
    "\n",
    "# I to wszystko! Zbudujmy model ze zdefiniowanych wyżej warstw\n",
    "model = Sequential()\n",
    "model.add(flatten_layer)\n",
    "model.add(matmul_layer)\n",
    "model.add(get_probas_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metoda optymalizacji\n",
    "- Keras musi wiedzieć, jaką funkcję straty chcemy minimalizować.\n",
    "- Musi także wiedzieć, jakiej metody ma użyć do minimalizacji\n",
    "- Dobra wiadomość: nie musimy umieć implementować tych elementów: keras o wszystko zadba!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skorzystamy ze standardowego zestawu w przypadku klasyfikacji: straty logistycznej i optymalizatora [Adam](google.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_straty = \"categorical_crossentropy\"\n",
    "optymalizator = \"adam\"\n",
    "\n",
    "# Model należy jeszcze skompilować, podając wybraną stratę i optymalizator\n",
    "model.compile(loss=f_straty, optimizer=optymalizator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uczenie:\n",
    "- Nasz model jest już kompletny!\n",
    "- Teraz wystarczy wywołać funkcję, która rozpocznie proces uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "liczba_iteracji = 5\n",
    "model.fit(X_train, Y_train, nb_epoch=liczba_iteracji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# jak sobie poradziliśmy?\n",
    "preds = model.predict_classes(X_test)\n",
    "acc   = np.mean(preds == y_test)\n",
    "\n",
    "plot_confusion_matrix(y_test, preds)\n",
    "print(\"\\nAccuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gdzie są sieci neuronowe?!\n",
    "\n",
    "- Powyższy model to zwykła regresja logistyczna w kerasie. Jak przejść od niej do uczenia głębokiego? \n",
    "- Proste: dodać więcej warstw!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(rozmiar, rozmiar, 1)))\n",
    "\n",
    "# pomiędzy warstwami mnożącymi macierze powinny znajdować się funkcje aktywacji\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.15)) # todo?\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\")) \n",
    "model.add(Dropout(0.15)) \n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\")) \n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "liczba_iteracji = 5\n",
    "model.fit(X_train, Y_train, nb_epoch=liczba_iteracji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# jak sobie poradziliśmy?\n",
    "preds = model.predict_classes(X_test)\n",
    "acc   = np.mean(preds == y_test)\n",
    "\n",
    "print(\"\\nAccuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sieci konwolucyjne\n",
    "- Dotychczas jako podstawowych elementów przetwarzania używaliśmy warstw, które wykonują proste mnożenie macierzy\n",
    "- Istnieją warstwy, które dedykowane są konkretnie rozpoznawaniu obrazów: tzw. warstwy konwolucyjne.\n",
    "- Dobieranie parametrów tych warstw to bardziej sztuka niż nauka i wymaga sporej wprawy. Dlatego nie zjamiemy się tym na tych zajęciach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Przykład sieci z warstwami konwolucyjnymi\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(8, 3, 3, border_mode='valid', input_shape=(rozmiar, rozmiar, 1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(8, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "liczba_iteracji = 5\n",
    "model.fit(X_train, Y_train, nb_epoch=liczba_iteracji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# jak sobie poradziliśmy?\n",
    "preds = model.predict_classes(X_test)\n",
    "acc   = np.mean(preds == y_test)\n",
    "\n",
    "print(\"\\nAccuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Prawdziwa\" sieć neuronowa\n",
    "- Keras udostępnia gotowe, wyuczone już modele.\n",
    "- Są to potężne sieci neuronowe, uczone tygodniami na olbrzymim zbiorze danych [Imagenet](http://www.image-net.org/)\n",
    "- Możemy wykorzystać tę sieć i szybko dostosować ją do własnych potrzeb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spróbujemy w krótkim czasie stworzyć model, który z dużą dokładnością (ok. 90%) nauczy się odróżniać koty od psów\n",
    "- W tym celu potrzebne nam będą dwa dodatkowe pojęcia: `data augmentation` oraz `bottleneck features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation\n",
    "- Jest to proces sztucznego \"powiększania\" zbioru dostępnych danych. \n",
    "- Powiedzmy, że mamy do dyspozycji 1000 zdjęć kotów. Aby nauczyć sieć neuronową, możemy ręcznie wygenerować na ich podstawie \"sztuczne\" dane: każdy z obrazków będziemy losowo obracać, skalować i rozciągać. W ten sposób dostarczymy więcej różnych zdjęć, nie ponosząc jednak kosztów fotografowania tysięcy kotów\n",
    "- Keras dostarcza gotową funkcję, `ImageDataGenerator`, która zajmie się tą transformacją za nas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottleneck features\n",
    "- Wiemy, że sieć neuronowa posiada warstwy\n",
    "- Wiemy, że warstwy pobierają pewne dane, dokonują ich transformacji, i przekazują dalej. \n",
    "- Okazuje się, iż każda taka warstwa uczy się rozpoznawać pewną klasę obiektów, a im głębiej w sieć, tym bardziej abstrakcyjne są owe klasy.\n",
    "- Przykładowo, sieć rozpoznająca samochody może w pierwszej warstwie nauczyć się odróżniania krawędzi, w drugiej -- pojedynczych części (takich jak koła, okna...), a w kolejnych -- całe kształty karoserii. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![car](img/car.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Możemy tę właśność wykorzystać: zamiast próbować odróżniać od siebie wielkie tablice pixeli (zdjęcia psów vs zdjęcia kotów), będziemy starali się odróżniać reprezentacje wygenerowane przez wytrenowaną wcześniej sieć neuronową. \n",
    "- Oznacza to, iż zamienimy każdy obrazek na jego reprezentację. Taka reprezentacja koduje informacje o tym, co sieć \"widzi\" w danym obrazie.\n",
    "- Sieć, której użyjemy, nosi nazwę `VGG16`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "target_shape          = img_width, img_height\n",
    "train_data_dir        = 'data/train'\n",
    "valid_data_dir        = 'data/validation'\n",
    "features_train        = 'data/bottleneck_features_train.npy'\n",
    "features_valid        = 'data/bottleneck_features_valid.npy'\n",
    "n_dataset_iter        = 4\n",
    "n_img_per_class       = 1000\n",
    "nb_train_samples      = n_img_per_class * 2 * n_dataset_iter\n",
    "nb_validation_samples = n_img_per_class * 2 * n_dataset_iter\n",
    "nb_epoch              = 15\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "    # pretrained network to produce bottleneck features\n",
    "    model = Sequential()\n",
    "    core = VGG16(input_shape=(img_width, img_height, 3), include_top=False, weights='imagenet')\n",
    "    \n",
    "    model.add(core)\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # boilerplate\n",
    "    if os.path.basename(features_train) not in os.listdir(\"data\"):\n",
    "        generator = datagen.flow_from_directory(train_data_dir, target_size=target_shape, batch_size=32, class_mode=None, shuffle=False)\n",
    "        bottleneck_features_train = model.predict_generator(generator, nb_train_samples)\n",
    "        np.save(open(features_train, 'wb'), bottleneck_features_train)\n",
    "\n",
    "    if os.path.basename(features_valid) not in os.listdir(\"data\"):\n",
    "        generator = datagen.flow_from_directory(valid_data_dir, target_size=target_shape, batch_size=32, class_mode=None, shuffle=False)    \n",
    "        bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples)\n",
    "        np.save(open(features_valid, 'wb'), bottleneck_features_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wczytanie wygenerowanych danych\n",
    "data_train = np.load(open(features_train, 'rb'))\n",
    "data_valid = np.load(open(features_valid, 'rb'))\n",
    "\n",
    "labels_train = np.array([y for _ in range(n_dataset_iter) for y in [0] * n_img_per_class + [1] * n_img_per_class])\n",
    "labels_valid = np.array([y for _ in range(n_dataset_iter) for y in [0] * n_img_per_class + [1] * n_img_per_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Budowa finalnego klasyfikatora\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=data_train.shape[1:], activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# kompilacja: wybieramy optymalizator i funkcję straty\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# uczymy!\n",
    "model.fit(data_train, labels_train, nb_epoch=nb_epoch, batch_size=32, validation_data=(data_valid, labels_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = model.predict_classes(data_valid).ravel()\n",
    "acc   = np.mean(preds == labels_valid)\n",
    "print(\"\\nOstateczne Accuracy: {:.1f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
